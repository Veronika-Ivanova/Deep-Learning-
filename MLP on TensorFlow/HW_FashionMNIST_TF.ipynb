{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW FashionMNIST TF",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbdL6J0zuKyx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI06YeOmu-uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPhBKSO3yv5P"
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-qZfXQ87e8D"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=10**4, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf9ziQFGC-G7"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_val = to_categorical(y_val)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgIZL6rtyi3u"
      },
      "source": [
        "def randomize(x, y):\n",
        "    \"\"\" Randomizes the order of data samples and their corresponding labels\"\"\"\n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    shuffled_x = x[permutation, :]\n",
        "    shuffled_y = y[permutation]\n",
        "    return shuffled_x, shuffled_y\n",
        "\n",
        "def get_next_batch(x, y, start, end):\n",
        "    x_batch = x[start:end]\n",
        "    y_batch = y[start:end]\n",
        "    return x_batch, y_batch"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI6578YVsEuF"
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA1fb03EsJuS"
      },
      "source": [
        "img_h = img_w = 28             # MNIST images are 28x28\n",
        "img_size_flat = img_h * img_w  # 28x28=784, the total number of pixels\n",
        "n_classes = 10                 # Number of classes, one class per digit\n",
        "# Hyper-parameters\n",
        "epochs = 20             # Total number of training epochs\n",
        "batch_size = 100        # Training batch size\n",
        "display_freq = 100      # Frequency of displaying the training results\n",
        "learning_rate = 0.005   # The optimization initial learning rate\n",
        "\n",
        "h1 = 400                # number of nodes in the 1st hidden layer"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHlhLQYM8fj_"
      },
      "source": [
        "X_train = np.reshape(X_train, [-1, img_size_flat])\n",
        "X_test = np.reshape(X_test, [-1, img_size_flat])\n",
        "X_val = np.reshape(X_val, [-1, img_size_flat])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrTH441esJxH"
      },
      "source": [
        "# weight and bias \n",
        "def weight_variable(name, shape):\n",
        "    \"\"\"\n",
        "    Create a weight variable with appropriate initialization\n",
        "    :param name: weight name\n",
        "    :param shape: weight shape\n",
        "    :return: initialized weight variable\n",
        "    \"\"\"\n",
        "    initer = tf.compat.v1.truncated_normal_initializer(stddev=0.01)\n",
        "    return tf.compat.v1.get_variable('W_' + name,\n",
        "                           dtype=tf.float32,\n",
        "                           shape=shape,\n",
        "                           initializer=initer)\n",
        "\n",
        "def bias_variable(name, shape):\n",
        "    \"\"\"\n",
        "    Create a bias variable with appropriate initialization\n",
        "    :param name: bias variable name\n",
        "    :param shape: bias variable shape\n",
        "    :return: initialized bias variable\n",
        "    \"\"\"\n",
        "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
        "    return tf.compat.v1.get_variable('b_' + name,\n",
        "                           dtype=tf.float32,\n",
        "                           initializer=initial)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz5GR4BdsJ0m"
      },
      "source": [
        "def fc_layer(x, num_units, name, use_relu=True):\n",
        "    \"\"\"\n",
        "    Create a fully-connected layer\n",
        "    :param x: input from previous layer\n",
        "    :param num_units: number of hidden units in the fully-connected layer\n",
        "    :param name: layer name\n",
        "    :param use_relu: boolean to add ReLU non-linearity (or not)\n",
        "    :return: The output array\n",
        "    \"\"\"\n",
        "    in_dim = x.get_shape()[1]\n",
        "    W = weight_variable(name, shape=[in_dim, num_units])\n",
        "    b = bias_variable(name, [num_units])\n",
        "    layer = tf.matmul(x, W)\n",
        "    layer += b\n",
        "    if use_relu:\n",
        "        layer = tf.nn.relu(layer)\n",
        "    return layer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECrhdZst1jvP"
      },
      "source": [
        "# Create the graph for the linear model\n",
        "# Placeholders for inputs (x) and outputs(y)\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "x = tf.compat.v1.placeholder(tf.float32, shape=[None, img_size_flat], name='X')\n",
        "y = tf.compat.v1.placeholder(tf.float32, shape=[None, n_classes], name='Y')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hyOvhCM1owq"
      },
      "source": [
        "# Create a fully-connected layer with h1 nodes as hidden layer\n",
        "fc1 = fc_layer(x, h1, 'FC1', use_relu=True)\n",
        "# Create a fully-connected layer with n_classes nodes as output layer\n",
        "output_logits = fc_layer(fc1, n_classes, 'OUT', use_relu=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJqp8h0j4a-E"
      },
      "source": [
        "# Define the loss function, optimizer, and accuracy\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output_logits), name='loss')\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n",
        "correct_prediction = tf.equal(tf.argmax(output_logits, 1), tf.argmax(y, 1), name='correct_pred')\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
        "\n",
        "# Network predictions\n",
        "cls_prediction = tf.argmax(output_logits, axis=1, name='predictions')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izng0KBq6Qd7"
      },
      "source": [
        "# Create the op for initializing all variables\n",
        "init = tf.compat.v1.global_variables_initializer()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUlme4_F-O7-",
        "outputId": "49bbc06f-011b-46af-c943-5d7c5dc1fcdc"
      },
      "source": [
        "print('x_train:\\t{}'.format(X_train.shape))\n",
        "print('y_train:\\t{}'.format(y_train.shape))\n",
        "print('x_train:\\t{}'.format(X_val.shape))\n",
        "print('y_valid:\\t{}'.format(y_val.shape))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train:\t(50000, 784)\n",
            "y_train:\t(50000, 10)\n",
            "x_train:\t(10000, 784)\n",
            "y_valid:\t(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsKBE75r6el8",
        "outputId": "c9ff831e-7c72-4456-9cb8-d15269d3f0cd"
      },
      "source": [
        "# Create an interactive session (to keep the session in the other cells)\n",
        "sess = tf.compat.v1.InteractiveSession()\n",
        "# Initialize all variables\n",
        "sess.run(init)\n",
        "# Number of training iterations in each epoch\n",
        "num_tr_iter = int(len(y_train) / batch_size)\n",
        "for epoch in range(epochs):\n",
        "    print('Training epoch: {}'.format(epoch + 1))\n",
        "    # Randomly shuffle the training data at the beginning of each epoch \n",
        "    X_train, y_train = randomize(X_train, y_train)\n",
        "    for iteration in range(num_tr_iter):\n",
        "        start = iteration * batch_size\n",
        "        end = (iteration + 1) * batch_size\n",
        "        x_batch, y_batch = get_next_batch(X_train, y_train, start, end)\n",
        "\n",
        "        # Run optimization op (backprop)\n",
        "        feed_dict_batch = {x: x_batch, y: y_batch}\n",
        "        sess.run(optimizer, feed_dict=feed_dict_batch)\n",
        "\n",
        "        if iteration % display_freq == 0:\n",
        "            # Calculate and display the batch loss and accuracy\n",
        "            loss_batch, acc_batch = sess.run([loss, accuracy],\n",
        "                                             feed_dict=feed_dict_batch)\n",
        "\n",
        "            print(\"iter {0:3d}:\\t Loss={1:.2f},\\tTraining Accuracy={2:.01%}\".\n",
        "                  format(iteration, loss_batch, acc_batch))\n",
        "\n",
        "    # Run validation after every epoch\n",
        "    feed_dict_valid = {x: X_val[:1000], y: y_val[:1000]}\n",
        "    loss_valid, acc_valid = sess.run([loss, accuracy], feed_dict=feed_dict_valid)\n",
        "    print('---------------------------------------------------------')\n",
        "    print(\"Epoch: {0}, validation loss: {1:.2f}, validation accuracy: {2:.01%}\".\n",
        "          format(epoch + 1, loss_valid, acc_valid))\n",
        "    print('---------------------------------------------------------')\n",
        " "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py:1761: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch: 1\n",
            "iter   0:\t Loss=6.44,\tTraining Accuracy=39.0%\n",
            "iter 100:\t Loss=0.53,\tTraining Accuracy=82.0%\n",
            "iter 200:\t Loss=0.40,\tTraining Accuracy=92.0%\n",
            "iter 300:\t Loss=0.41,\tTraining Accuracy=81.0%\n",
            "iter 400:\t Loss=0.40,\tTraining Accuracy=87.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 1, validation loss: 0.42, validation accuracy: 85.4%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 2\n",
            "iter   0:\t Loss=0.36,\tTraining Accuracy=83.0%\n",
            "iter 100:\t Loss=0.37,\tTraining Accuracy=85.0%\n",
            "iter 200:\t Loss=0.40,\tTraining Accuracy=85.0%\n",
            "iter 300:\t Loss=0.42,\tTraining Accuracy=86.0%\n",
            "iter 400:\t Loss=0.45,\tTraining Accuracy=87.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 2, validation loss: 0.43, validation accuracy: 84.1%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 3\n",
            "iter   0:\t Loss=0.26,\tTraining Accuracy=90.0%\n",
            "iter 100:\t Loss=0.37,\tTraining Accuracy=90.0%\n",
            "iter 200:\t Loss=0.36,\tTraining Accuracy=87.0%\n",
            "iter 300:\t Loss=0.35,\tTraining Accuracy=85.0%\n",
            "iter 400:\t Loss=0.27,\tTraining Accuracy=89.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 3, validation loss: 0.44, validation accuracy: 85.3%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 4\n",
            "iter   0:\t Loss=0.49,\tTraining Accuracy=83.0%\n",
            "iter 100:\t Loss=0.33,\tTraining Accuracy=89.0%\n",
            "iter 200:\t Loss=0.29,\tTraining Accuracy=91.0%\n",
            "iter 300:\t Loss=0.26,\tTraining Accuracy=90.0%\n",
            "iter 400:\t Loss=0.28,\tTraining Accuracy=87.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 4, validation loss: 0.43, validation accuracy: 86.6%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 5\n",
            "iter   0:\t Loss=0.27,\tTraining Accuracy=91.0%\n",
            "iter 100:\t Loss=0.30,\tTraining Accuracy=88.0%\n",
            "iter 200:\t Loss=0.37,\tTraining Accuracy=89.0%\n",
            "iter 300:\t Loss=0.27,\tTraining Accuracy=89.0%\n",
            "iter 400:\t Loss=0.36,\tTraining Accuracy=87.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 5, validation loss: 0.39, validation accuracy: 86.2%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 6\n",
            "iter   0:\t Loss=0.25,\tTraining Accuracy=89.0%\n",
            "iter 100:\t Loss=0.45,\tTraining Accuracy=87.0%\n",
            "iter 200:\t Loss=0.32,\tTraining Accuracy=87.0%\n",
            "iter 300:\t Loss=0.28,\tTraining Accuracy=89.0%\n",
            "iter 400:\t Loss=0.27,\tTraining Accuracy=88.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 6, validation loss: 0.41, validation accuracy: 85.7%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 7\n",
            "iter   0:\t Loss=0.17,\tTraining Accuracy=93.0%\n",
            "iter 100:\t Loss=0.35,\tTraining Accuracy=90.0%\n",
            "iter 200:\t Loss=0.28,\tTraining Accuracy=89.0%\n",
            "iter 300:\t Loss=0.24,\tTraining Accuracy=91.0%\n",
            "iter 400:\t Loss=0.42,\tTraining Accuracy=86.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 7, validation loss: 0.40, validation accuracy: 87.0%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 8\n",
            "iter   0:\t Loss=0.24,\tTraining Accuracy=92.0%\n",
            "iter 100:\t Loss=0.23,\tTraining Accuracy=93.0%\n",
            "iter 200:\t Loss=0.42,\tTraining Accuracy=85.0%\n",
            "iter 300:\t Loss=0.47,\tTraining Accuracy=79.0%\n",
            "iter 400:\t Loss=0.46,\tTraining Accuracy=84.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 8, validation loss: 0.42, validation accuracy: 86.4%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 9\n",
            "iter   0:\t Loss=0.25,\tTraining Accuracy=91.0%\n",
            "iter 100:\t Loss=0.34,\tTraining Accuracy=87.0%\n",
            "iter 200:\t Loss=0.28,\tTraining Accuracy=91.0%\n",
            "iter 300:\t Loss=0.47,\tTraining Accuracy=84.0%\n",
            "iter 400:\t Loss=0.33,\tTraining Accuracy=88.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 9, validation loss: 0.44, validation accuracy: 85.4%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 10\n",
            "iter   0:\t Loss=0.21,\tTraining Accuracy=92.0%\n",
            "iter 100:\t Loss=0.32,\tTraining Accuracy=87.0%\n",
            "iter 200:\t Loss=0.30,\tTraining Accuracy=90.0%\n",
            "iter 300:\t Loss=0.41,\tTraining Accuracy=87.0%\n",
            "iter 400:\t Loss=0.31,\tTraining Accuracy=89.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 10, validation loss: 0.46, validation accuracy: 86.2%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 11\n",
            "iter   0:\t Loss=0.22,\tTraining Accuracy=93.0%\n",
            "iter 100:\t Loss=0.39,\tTraining Accuracy=85.0%\n",
            "iter 200:\t Loss=0.40,\tTraining Accuracy=87.0%\n",
            "iter 300:\t Loss=0.30,\tTraining Accuracy=89.0%\n",
            "iter 400:\t Loss=0.21,\tTraining Accuracy=92.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 11, validation loss: 0.46, validation accuracy: 86.7%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 12\n",
            "iter   0:\t Loss=0.34,\tTraining Accuracy=88.0%\n",
            "iter 100:\t Loss=0.24,\tTraining Accuracy=92.0%\n",
            "iter 200:\t Loss=0.47,\tTraining Accuracy=85.0%\n",
            "iter 300:\t Loss=0.29,\tTraining Accuracy=90.0%\n",
            "iter 400:\t Loss=0.28,\tTraining Accuracy=89.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 12, validation loss: 0.48, validation accuracy: 85.0%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 13\n",
            "iter   0:\t Loss=0.25,\tTraining Accuracy=87.0%\n",
            "iter 100:\t Loss=0.33,\tTraining Accuracy=88.0%\n",
            "iter 200:\t Loss=0.16,\tTraining Accuracy=94.0%\n",
            "iter 300:\t Loss=0.25,\tTraining Accuracy=92.0%\n",
            "iter 400:\t Loss=0.29,\tTraining Accuracy=91.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 13, validation loss: 0.44, validation accuracy: 87.1%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 14\n",
            "iter   0:\t Loss=0.33,\tTraining Accuracy=91.0%\n",
            "iter 100:\t Loss=0.39,\tTraining Accuracy=87.0%\n",
            "iter 200:\t Loss=0.35,\tTraining Accuracy=87.0%\n",
            "iter 300:\t Loss=0.12,\tTraining Accuracy=96.0%\n",
            "iter 400:\t Loss=0.52,\tTraining Accuracy=77.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 14, validation loss: 0.49, validation accuracy: 83.9%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 15\n",
            "iter   0:\t Loss=0.32,\tTraining Accuracy=89.0%\n",
            "iter 100:\t Loss=0.26,\tTraining Accuracy=87.0%\n",
            "iter 200:\t Loss=0.31,\tTraining Accuracy=86.0%\n",
            "iter 300:\t Loss=0.29,\tTraining Accuracy=89.0%\n",
            "iter 400:\t Loss=0.24,\tTraining Accuracy=94.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 15, validation loss: 0.44, validation accuracy: 87.8%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 16\n",
            "iter   0:\t Loss=0.22,\tTraining Accuracy=89.0%\n",
            "iter 100:\t Loss=0.27,\tTraining Accuracy=93.0%\n",
            "iter 200:\t Loss=0.33,\tTraining Accuracy=87.0%\n",
            "iter 300:\t Loss=0.36,\tTraining Accuracy=86.0%\n",
            "iter 400:\t Loss=0.27,\tTraining Accuracy=89.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 16, validation loss: 0.41, validation accuracy: 87.8%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 17\n",
            "iter   0:\t Loss=0.38,\tTraining Accuracy=86.0%\n",
            "iter 100:\t Loss=0.32,\tTraining Accuracy=88.0%\n",
            "iter 200:\t Loss=0.28,\tTraining Accuracy=90.0%\n",
            "iter 300:\t Loss=0.29,\tTraining Accuracy=87.0%\n",
            "iter 400:\t Loss=0.47,\tTraining Accuracy=84.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 17, validation loss: 0.40, validation accuracy: 88.7%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 18\n",
            "iter   0:\t Loss=0.28,\tTraining Accuracy=87.0%\n",
            "iter 100:\t Loss=0.25,\tTraining Accuracy=89.0%\n",
            "iter 200:\t Loss=0.33,\tTraining Accuracy=89.0%\n",
            "iter 300:\t Loss=0.28,\tTraining Accuracy=92.0%\n",
            "iter 400:\t Loss=0.18,\tTraining Accuracy=94.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 18, validation loss: 0.48, validation accuracy: 86.8%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 19\n",
            "iter   0:\t Loss=0.26,\tTraining Accuracy=89.0%\n",
            "iter 100:\t Loss=0.38,\tTraining Accuracy=86.0%\n",
            "iter 200:\t Loss=0.27,\tTraining Accuracy=95.0%\n",
            "iter 300:\t Loss=0.39,\tTraining Accuracy=87.0%\n",
            "iter 400:\t Loss=0.27,\tTraining Accuracy=91.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 19, validation loss: 0.45, validation accuracy: 87.1%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 20\n",
            "iter   0:\t Loss=0.32,\tTraining Accuracy=89.0%\n",
            "iter 100:\t Loss=0.30,\tTraining Accuracy=90.0%\n",
            "iter 200:\t Loss=0.43,\tTraining Accuracy=87.0%\n",
            "iter 300:\t Loss=0.30,\tTraining Accuracy=90.0%\n",
            "iter 400:\t Loss=0.28,\tTraining Accuracy=88.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 20, validation loss: 0.46, validation accuracy: 87.2%\n",
            "---------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piFz1j3H6hjG",
        "outputId": "ed2a132c-b59b-488c-a795-9e03f825dedf"
      },
      "source": [
        "# Test the network after training\n",
        "# Accuracy\n",
        "feed_dict_test = {x: X_test[:1000], y: y_test[:1000]}\n",
        "loss_test, acc_test = sess.run([loss, accuracy], feed_dict=feed_dict_test)\n",
        "print('---------------------------------------------------------')\n",
        "print(\"Test loss: {0:.2f}, test accuracy: {1:.01%}\".format(loss_test, acc_test))\n",
        "print('---------------------------------------------------------')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------\n",
            "Test loss: 0.45, test accuracy: 86.2%\n",
            "---------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C21U793EQX4"
      },
      "source": [
        "sess.close()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipj6a64aFnU6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}